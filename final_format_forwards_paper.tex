% Template for PLoS
% Version 3.5 March 2018
%
% % % % % % % % % % % % % % % % % % % % % %
%
% -- IMPORTANT NOTE
%
% This template contains comments intended 
% to minimize problems and delays during our production 
% process. Please follow the template instructions
% whenever possible.
%
% % % % % % % % % % % % % % % % % % % % % % % 
%
% Once your paper is accepted for publication, 
% PLEASE REMOVE ALL TRACKED CHANGES in this file 
% and leave only the final text of your manuscript. 
% PLOS recommends the use of latexdiff to track changes during review, as this will help to maintain a clean tex file.
% Visit https://www.ctan.org/pkg/latexdiff?lang=en for info or contact us at latex@plos.org.
%
%
% There are no restrictions on package use within the LaTeX files except that 
% no packages listed in the template may be deleted.
%
% Please do not include colors or graphics in the text.
%
% The manuscript LaTeX source should be contained within a single file (do not use \input, \externaldocument, or similar commands).
%
% % % % % % % % % % % % % % % % % % % % % % %
%
% -- FIGURES AND TABLES
%
% Please include tables/figure captions directly after the paragraph where they are first cited in the text.
%
% DO NOT INCLUDE GRAPHICS IN YOUR MANUSCRIPT
% - Figures should be uploaded separately from your manuscript file. 
% - Figures generated using LaTeX should be extracted and removed from the PDF before submission. 
% - Figures containing multiple panels/subfigures must be combined into one image file before submission.
% For figure citations, please use "Fig" instead of "Figure".
% See http://journals.plos.org/plosone/s/figures for PLOS figure guidelines.
%
% Tables should be cell-based and may not contain:
% - spacing/line breaks within cells to alter layout or alignment
% - do not nest tabular environments (no tabular environments within tabular environments)
% - no graphics or colored text (cell background color/shading OK)
% See http://journals.plos.org/plosone/s/tables for table guidelines.
%
% For tables that exceed the width of the text column, use the adjustwidth environment as illustrated in the example table in text below.
%
% % % % % % % % % % % % % % % % % % % % % % % %
%
% -- EQUATIONS, MATH SYMBOLS, SUBSCRIPTS, AND SUPERSCRIPTS
%
% IMPORTANT
% Below are a few tips to help format your equations and other special characters according to our specifications. For more tips to help reduce the possibility of formatting errors during conversion, please see our LaTeX guidelines at http://journals.plos.org/plosone/s/latex
%
% For inline equations, please be sure to include all portions of an equation in the math environment.  For example, x$^2$ is incorrect; this should be formatted as $x^2$ (or $\mathrm{x}^2$ if the romanized font is desired).
%
% Do not include text that is not math in the math environment. For example, CO2 should be written as CO\textsubscript{2} instead of CO$_2$.
%
% Please add line breaks to long display equations when possible in order to fit size of the column. 
%
% For inline equations, please do not include punctuation (commas, etc) within the math environment unless this is part of the equation.
%
% When adding superscript or subscripts outside of brackets/braces, please group using {}.  For example, change "[U(D,E,\gamma)]^2" to "{[U(D,E,\gamma)]}^2". 
%
% Do not use \cal for caligraphic font.  Instead, use \mathcal{}
%
% % % % % % % % % % % % % % % % % % % % % % % % 
%
% Please contact latex@plos.org with any questions.
%
% % % % % % % % % % % % % % % % % % % % % % % %

\documentclass[10pt,letterpaper]{article}
\usepackage[top=0.85in,left=2.75in,footskip=0.75in]{geometry}

% amsmath and amssymb packages, useful for mathematical formulas and symbols
\usepackage{amsmath,amssymb}

% Use adjustwidth environment to exceed column width (see example table in text)
\usepackage{changepage}

% Use Unicode characters when possible
\usepackage[utf8x]{inputenc}

% textcomp package and marvosym package for additional characters
\usepackage{textcomp,marvosym}

% cite package, to clean up citations in the main text. Do not remove.
\usepackage{cite}

% Use nameref to cite supporting information files (see Supporting Information section for more info)
\usepackage[hidelinks]{hyperref}
\usepackage{nameref}

% line numbers
\usepackage[right]{lineno}

% ligatures disabled
\usepackage{microtype}
\DisableLigatures[f]{encoding = *, family = * }

% color can be used to apply background shading to table cells only
\usepackage[table]{xcolor}

% array package and thick rules for tables
\usepackage{array}

% create "+" rule type for thick vertical lines
\newcolumntype{+}{!{\vrule width 2pt}}

% create \thickcline for thick horizontal lines of variable length
\newlength\savedwidth
\newcommand\thickcline[1]{%
  \noalign{\global\savedwidth\arrayrulewidth\global\arrayrulewidth 2pt}%
  \cline{#1}%
  \noalign{\vskip\arrayrulewidth}%
  \noalign{\global\arrayrulewidth\savedwidth}%
}

% \thickhline command for thick horizontal lines that span the table
\newcommand\thickhline{\noalign{\global\savedwidth\arrayrulewidth\global\arrayrulewidth 2pt}%
\hline
\noalign{\global\arrayrulewidth\savedwidth}}


% Remove comment for double spacing
%\usepackage{setspace} 
%\doublespacing

% Text layout
\raggedright
\setlength{\parindent}{0.5cm}
\textwidth 5.25in 
\textheight 8.75in

% Bold the 'Figure #' in the caption and separate it from the title/caption with a period
% Captions will be left justified
\usepackage[aboveskip=1pt,labelfont=bf,labelsep=period,justification=raggedright,singlelinecheck=off]{caption}
\renewcommand{\figurename}{Fig}

% Use the PLoS provided BiBTeX style
\bibliographystyle{plos2015}

% Remove brackets from numbering in List of References
\makeatletter
\renewcommand{\@biblabel}[1]{\quad#1.}
\makeatother

% Header and Footer with logo
\usepackage{lastpage,fancyhdr,graphicx}
\usepackage{epstopdf}
%\pagestyle{myheadings}
\pagestyle{fancy}
\fancyhf{}
%\setlength{\headheight}{27.023pt}
%\lhead{\includegraphics[width=2.0in]{PLOS-submission.eps}}
\rfoot{\thepage/\pageref{LastPage}}
\renewcommand{\headrulewidth}{0pt}
\renewcommand{\footrule}{\hrule height 2pt \vspace{2mm}}
\fancyheadoffset[L]{2.25in}
\fancyfootoffset[L]{2.25in}
\lfoot{\today}

%% Include all macros below


\usepackage{enumitem}
\usepackage{listings}


\newcommand{\R}{\mathbb{R}}
\newcommand{\Q}{\mathbb{Q}}
\newcommand{\Z}{\mathbb{Z}}
\newcommand{\N}{\mathbb{N}}
\newcommand{\C}{\mathbb{C}}

\renewcommand{\P}{\mathbb{P}}
\newcommand{\E}{\mathbb{E}}
\newcommand{\var}{\mathop{\mbox{Var}}}
\newcommand{\cov}{\mathop{\mbox{cov}}}
%\newcommand{\det}{\mathop{\mbox{det}}}
\newcommand{\supp}{\mathop{\mbox{supp}}}
\newcommand{\sgn}{\mathop{\mbox{sgn}}}
\newcommand{\EE}[1]{\E\!\left[#1\right]}
\newcommand{\PP}[1]{\P\!\left\{#1\right\}}
\newcommand{\PPP}[2]{\P_{#1}\!\left\{#2\right\}}
\newcommand{\EEE}[2]{\E_{#1}\!\left[#2\right]}
\newcommand{\EEsup}[2]{\E^{#1}\!\left[#2\right]}

\newcommand{\bone}{\mathbf{1}}

% These macros are borrowed from TAOCPMAC.tex
\newcommand{\slug}{\hbox{\kern1.5pt\vrule width2.5pt height6pt depth1.5pt\kern1.5pt}}
\def\xskip{\hskip 7pt plus 3pt minus 4pt}
\newdimen\algindent
\newif\ifitempar \itempartrue % normally true unless briefly set false
\def\algindentset#1{\setbox0\hbox{{\bf #1.\kern.25em}}\algindent=\wd0\relax}
\def\algbegin #1 #2{\algindentset{#21}\alg #1 #2} % when steps all have 1 digit
\def\aalgbegin #1 #2{\algindentset{#211}\alg #1 #2} % when 10 or more steps
\def\alg#1(#2). {\medbreak % Usage: \algbegin Algorithm A (algname). This...
  \noindent{\bf#1}({\it#2\/}).\xskip\ignorespaces}
\def\kalgstep#1.{\ifitempar\smallskip\noindent\else\itempartrue
   \hskip-\parindent\fi
   \hbox to\algindent{\bf\hfil #1.\kern.25em}%
   \hangindent=\algindent\hangafter=1\ignorespaces}

\newcommand{\algstep}[3]{\kalgstep #1 [#2] #3 }
\newenvironment{taocpalg}[3]{%
\vspace{1em}%
\algbegin Algorithm #1. ({#2}). #3 }
{\vspace{1em}}

\newcommand{\randomuniform}[0]{\mathcal{R}_U}
\newcommand{\randomdiscrete}[0]{\mathcal{R}_D}
\newcommand{\algref}[1]{#1}

% \newcommand{\tablenotation}[1]{\mathcal{#1}}
% \newcommand{\tableaddrow}[0]{\mbox{add}}
\newcommand{\simupop}{\texttt{simuPOP}}
\newcommand{\fwdpp}{\texttt{fwdpp}}
\newcommand{\fwdpy}{\texttt{fwdpy11}}
\newcommand{\justc}{\texttt{C}}
\newcommand{\cpp}{\texttt{C++}}
\newcommand{\msprime}{\texttt{msprime}}
\newcommand{\tskit}{\texttt{tskit}}
\newcommand{\ftprime}{\texttt{ftprime}}
\newcommand{\nodes}{\texttt{nodes}}
\newcommand{\edgesets}{\texttt{edgesets}}
\newcommand{\sites}{\texttt{sites}}
\newcommand{\mutations}{\texttt{mutations}}
\newcommand{\setdiff}{\smallsetminus}
\newcommand{\Nt}{\mathcal{N}}  % node table
\newcommand{\Et}{\mathcal{E}}  % edge table
\newcommand{\St}{\mathcal{S}}  % site table
\newcommand{\Mt}{\mathcal{M}}  % mutation table
\newcommand{\Al}{\mathcal{A}}  % list of ancestors
\newcommand{\priorityq}[1]{\mbox{\textbf{PriorityQueue}}({#1})}
\newcommand{\listnew}[1]{\mbox{\textbf{List}}(#1)}
\newcommand{\pqpush}[2]{#1.\mbox{\textbf{push}}(#2)}
\newcommand{\pqpop}[1]{#1.\mbox{\textbf{pop}}()}
\newcommand{\listappend}[2]{#1.\mbox{\textbf{append}}(#2)}
\newcommand{\ancsegment}[1]{\mbox{\textbf{Segment}}(#1)}
\newcommand{\taddrow}[2]{#1.\mbox{\textbf{addrow}}(#2)}
\newcommand{\attrparent}[1]{#1.\mbox{parent}}
\newcommand{\attrchild}[1]{#1.\mbox{child}}
\newcommand{\attrleft}[1]{#1.\mbox{left}}
\newcommand{\attrright}[1]{#1.\mbox{right}}
\newcommand{\attrnode}[1]{#1.\mbox{node}}
% mbox to avoid hyphenating
\newcommand{\tsimplify}[1]{\mbox{\textbf{simplify}}(#1)}
\newcommand{\tsort}[1]{\mbox{\textbf{sort}}(#1)}
\newcommand{\tnodetable}[1]{\mbox{\textbf{NodeTable}}(#1)}
\newcommand{\tedgetable}[1]{\mbox{\textbf{EdgeTable}}(#1)}

\usepackage{color}
\newcommand{\krt}[1]{{\em \color{green} #1}}
\newcommand{\plr}[1]{{\em \color{blue} #1}}
\newcommand{\jk}[1]{{\em \color{red} #1}}
\newcommand{\jda}[1]{{\em \color{cyan} #1}}

% % stuff for submission
\usepackage[nofiglist,nomarkers,figuresonly]{endfloat}
\newcommand\citet{\cite}
\newcommand\citep{\cite}
\renewcommand\includegraphics{\relax}
\renewcommand{\includegraphics}[2][]{\relax}
\newcommand{\revpoint}[2]{}

%% END MACROS SECTION


\begin{document}
\vspace*{0.2in}
% Title must be 250 characters or less.
\begin{flushleft}
{\Large
\textbf\newline{Efficient pedigree recording for fast population genetics simulation}
}
\newline
% Insert author names, affiliations and corresponding author email (do not include titles, positions, or degrees).
\\
    Jerome Kelleher\textsuperscript{1},
    Kevin R.\ Thornton\textsuperscript{2},
    Jaime Ashander\textsuperscript{3},
    Peter L.\ Ralph\textsuperscript{4,*},
\\
\bigskip
\textbf{1} 
    {Big Data Institute, University of Oxford, UK}
\\
\textbf{2} 
    {Ecology and Evolutionary Biology, University of California at Irvine, USA}
\\
\textbf{3} 
    {Ecology and Evolutionary Biology, University of California at Los Angeles, USA}
\\
\textbf{4} 
    {Institute for Ecology and Evolution, University of Oregon, USA}
\bigskip

% Use the asterisk to denote corresponding authorship and provide email address in note below.
\textbf{*} \url{plr@uoregon.edu}

\end{flushleft}
% Please keep the abstract below 300 words
\section*{Abstract}
    In this paper we describe how to efficiently record the entire genetic history of a population
    in forwards-time, individual-based population genetics simulations with arbitrary breeding models,
    population structure and demography.
    This approach dramatically reduces the computational burden of tracking individual genomes
    by allowing us to simulate only those loci that may affect reproduction
    (those having non-neutral variants).
    The genetic history of the population is recorded as a succinct tree sequence
    as introduced in the software package msprime,
    on which neutral mutations can be quickly placed afterwards.
    Recording the results of each breeding event requires storage that grows linearly with time,
    but there is a great deal of redundancy in this information.
    We solve this storage problem by providing an algorithm to quickly `simplify'
    a tree sequence by removing this irrelevant history for a given set of genomes.
    By periodically simplifying the history with respect to the extant population,
    we show that the total storage space required is modest
    and overall large efficiency gains can be made over classical forward-time simulations.
    We implement a general-purpose framework for recording and simplifying genealogical data,
    which can be used to make simulations of any population model more efficient.
    We modify two popular forwards-time simulation frameworks to use this new approach
    and observe efficiency gains in large, whole-genome simulations of one to two orders of magnitude.
    In addition to speed, our method for recording pedigrees has several advantages:
    (1) All marginal genealogies of the simulated individuals are recorded, rather than just genotypes.
    (2) A population of $N$ individuals with $M$ polymorphic sites
        can be stored in $O(N \log N + M)$ space,
        making it feasible to store a simulation's entire final generation
        as well as its history.
    (3) A simulation can easily be initialized with a more efficient coalescent simulation 
        of deep history.
    The software for recording and processing tree sequences is named tskit.


% Please keep the Author Summary between 150 and 200 words
% Use first person. PLOS ONE authors please skip this step. 
% Author Summary not valid for PLOS ONE submissions.   
\section*{Author Summary}

Sexually reproducing organisms are related to the others in their species
by the complex web of parent-offspring relationships that constitute the pedigree.
In this paper, we describe a way to record all of these relationships,
as well as how genetic material is passed down through the pedigree,
during a forwards-time population genetic simulation.
To make effective use of this information,
we describe both efficient storage methods for this embellished pedigree
as well as a way to remove all information 
that is irrelevant to the genetic history of a given set of individuals,
which dramatically reduces the required amount of storage space.
Storing this information allows us to produce whole-genome sequence
from simulations of large populations in which we have not explicitly recorded new genomic mutations;
we find that this results in computational run times of up to 50 times faster
than simulations forced to explicitly carry along that information.

\linenumbers

%%%%%%%%%%%%%%%%%%%%%%
\section*{Introduction}

Since the 1980's, coalescent theory has enabled computer simulation of the results of population genetics models
identical to that which would be produced by large, randomly mating populations over long periods of time
without actually requiring simulation of so many generations or meioses.
Coalescent theory thus had three transformative effects on population genetics:
first, giving researchers better conceptual tools to describe \emph{gene trees}
and thus bringing within-population trees into better focus;
second,
producing analytical methods to estimate parameters of interest from genetic data; \revpoint{1}{5}
and finally, providing a computationally feasible method
to produce computer simulations of population genetics processes.
However, these powerful advances came with substantial caveats:
the backwards-in-time processes that are described by coalescent theory
are only \emph{Markovian}, and thus feasible to work with,
under the following important assumptions: \revpoint{2}{3}
(a) random mating,
(b) neutrality,
(c) large population size,
and (d) small sample size relative to the population size.
The first two assumptions can be side-stepped to a limited extent \citep{hudson1990gene, Neuhauser1997-nn},
but it remains a challenge to map results of coalescent models
onto species that are distributed across continuous geographical
space~\citep{barton2010new,kelleher2014coalescent}
and/or have large numbers of loci under various sorts of selection.
Usually, the relationship between the life history of a species --
fecundity and mortality schedules, density-dependent effects on fitness, and demographic fluctuations --
are all absorbed into a single compound parameter, the coalescence rate.
More mechanistic models are possible using ``forwards--backwards'' simulations,
that first simulate population size changes forwards in time
and then thread a coalescent backwards \citep{ray2010splatche2}, \revpoint{1}{3}
but these still require the assumptions above to be met for each subpopulation.
The last assumption is no longer safe, either --
for example, a recent study~\citep{martin2017human}
simulated 600,000 samples of human chromosome 20 to examine biases in GWAS.
Several studies have now shown that in samples approaching the size of the population,
genealogical properties may be distorted relative to the coalescent expectation
\citep{wakeley2003gene,maruvka2011recovering,bhaskar2014distortion}.
These considerations, and increasing computational power, have led to a resurgence of
interest in large forwards-time, individual-based simulations.
For instance, \citet{harris2016genetic} used SLiM \citep{slim} to simulate ten thousand human exomes
to assess the impact of genetic load and Neanderthal introgression on human genetic diversity.
\cite{Sanjak2017-ko} used
\fwdpp{} \citep{fwdpp} to simulate a series of models of quantitative traits under mutation-selection balance with
population sizes of $2 \times 10^4$ diploids in stable populations and populations growing up to around $5
\times 10^5$ individuals, using the output to explore the relationship between the genotype/phenotype model and GWAS
outcomes.

Modern computing power easily allows simulations of birth, death and reproduction
in a population having even hundreds of millions of individuals.
However, if our interest lies in the resulting genetic patterns of variation
-- and often, the point of such simulations is to compare to real data --
then such simulations must record each individual's genome.
As samples of most species' genomes harbor tens or hundreds of millions of variant sites,
carrying full genotypes for even modest numbers of individuals through a simulation
can quickly become prohibitive.
To make matters worse,
a population of size $N$ must be simulated across many multiples of $N$ generations
to produce stable genetic patterns \citep{wright1931evolution, wakeley2005coalescent}.
Because of this computational burden, even the fastest simulation frameworks such as
SLiM 2~\citep{haller2017flexible} and fwdpp~\citep{fwdpp}
can ``only'' simulate tens of megabases of sequence in tens of thousands of individuals
for tens of thousands of generations.
%% plr: not sure why we need to say these things here?
% and there are still near-order-of-magnitude performance differences between these implementations~\citep{haller2017flexible}.
In practice, current state-of-the-art simulation software may take on the order of
weeks to simulate models of large genomic regions without selection~\citep{fwdpp,Hernandez2015-wf},
and existing simulation engines differ in how efficiently they
calculate fitnesses in models with selection~\citep{fwdpp}.
These population and region sizes are still substantially short of whole genomes
(hundreds to thousands of megabases)
for many biological population sizes of interest.

However, it is thought that most genetic variation is selectively neutral (or nearly so).
By definition, neutral alleles carried by individuals in a population
do not affect the population process.
For this reason, if one records the entire genealogical history of a population over the course of a simulation,
simply laying down neutral mutations on top of that history afterwards
is equivalent to having generated them during the simulation:
it does not matter if we generate each generation's mutations during the simulation, or afterwards.
To add mutations after the fact, we need to know the genealogical trees relating all sampled individuals
at each position along the genome.
Combined with ancestral genotypes and the origins of new mutations,
these trees completely specify the genomic sequence of any individual in the population at any time.
To obtain this information, we record from forward simulation the \emph{population pedigree} --
the complete history of parent-offspring relationships of an entire population
going back to a remote time -- and the genetic outcomes of each ancestral meiosis,
periodically discarding all information irrelevant to the genetic history
of the extant population.
The information in this embellished pedigree is stored as a \emph{succinct tree sequence}
(or, for brevity, ``tree sequence''),
which contains all the information necessary
to construct the genealogical tree that relates each individual to every other
at each position on the genome.

The idea of storing genealogical information to speed up simulations is not new.
It was implemented in AnA-FiTS~\citep{aberer2013rapid},
but without the critical step of discarding irrelevant genealogical information.
\citet{padhukasahasram2008exploring} obtained impressive speedups for a Wright--Fisher simulation
by keeping track of genealogies over the preceding 8 generations
and only tracking neutral genotypes for those segments having descendants across this window.
Our approach is similar, but uses genealogies across the entire duration of the simulation.
The embellished pedigree is equivalent to the \emph{ancestral recombination graph},
or {ARG} \citep{griffiths1991two,griffiths1997ancestral},
which has been the subject of substantial study
% under the assumptions of coalescent theory
\citep{wiuf1997number,wiuf1999ancestry,marjoram2006coalescent,wilton2015smc}.
However, it is unclear if an ARG-based approach would share
the computational advantages of the data structures we use here~\citep{kelleher2016efficient}.

% However, the properties of the ARG as a computational structure have not
% been studied and, despite several efforts to standardise a common
% format~\citep{morin2006netgen,mcgill2013graphml}, % TODO check these refs against others in msprime paper
% ARGs are rarely used in practise.
% In contrast, the algorithmic properties of tree sequence
% algorithms have been explored in detail~\citep{kelleher2016efficient},
% contributing substantially to the efficiency of the \msprime{} coalescent simulator.

In this paper, we describe a storage method for \emph{succinct tree sequences}
(and hence, genome sequence) as well as an algorithm for simplifying these.
The data structure is \emph{succinct} in the sense that its space usage is close to optimal,
while still allowing efficient retrieval of information (see, e.g., \citet{gog2014theory}).
We also describe how these tools can efficiently record,
and later process, the embellished population pedigree from a forwards-time simulation.
While providing substantial savings in computational time and space, our methods provide 
in principle much more information than simply simulating the genomes -- the tree sequence
encodes all marginal genealogies of individuals living at the end of the simulation.
These marginal genealogies enable fast data storage and processing,
but also provide additional information that can be used to better understand
the notoriously complex dynamics of population genetics. \revpoint{1}{4}
Although we were motivated by a need for more efficient genomic simulations,
these tools may prove more widely useful.
This work originated as improvements to the algorithmic tools and data structures 
in the coalescent simulator \msprime{}; \linelabel{msprime_rel}
the software tools described here for working with tree sequences are referred to as \tskit{};
they are currently bundled with the Python package \msprime{},
but will soon be separately available as a Python API and an embeddable C library.



%%%%%%%%%%%%%%%%%%%%%
\section*{Results}


The strategy described above is only of interest if it is computationally feasible.
Therefore,
we begin by benchmarking the performance improvement achieved by this method,
implemented using the forwards-time simulation library \fwdpp{} \citep{fwdpp}
and tree sequence tools implemented in \tskit{}.
Then, we describe the conceptual and algorithmic foundations for the method:
(a) a format, implemented in the \tskit{} Python API,
for recording tree sequences efficiently in several \emph{tables};
(b) an algorithm to record these tables during a forwards-time simulation;
and (c) an algorithm to \emph{simplify} a tree sequence, i.e., remove redundant information.
Finally, we analyze the run time and space complexity of our general-purpose method.


%%%%%%
\subsection*{Simulation benchmarks}

To measure the performance gains from recording the pedigree we ran simulations
both with and without recording.
(Although we record more than just the parent--offspring relationships of the pedigree,
for brevity we refer to the method as ``pedigree recording''.)
All simulations used \fwdpp{} to implement a discrete-time Wright-Fisher population of $N$ diploid individuals,
simulated for $10N$ generations (details below).
Simulations without pedigree recording introduced neutral mutations at a rate
equal to the recombination rate,
so $\mu = r$, where $\mu$ and $r$ are the expected per-generation number of mutations per gamete
and recombination breakpoints per diploid, respectively.
Simulations with pedigree recording introduced neutral mutations at the same rate
retrospectively, as described below, resulting in statistically identical simulation results.
% Both mutations and recombinations occur as Poisson processes with respective means $\mu$ and $r$,
% and we used the infinitely-many sites mutation model \citep{Kimura1969-uc}.
We ran simulations with different values of $N$ and varied the size of the genomic region according to the scaled recombination
parameter $\rho = 4Nr$.
%% this was said already:
% When simulating neutral mutations, we kept the scaled mutation parameter, $\theta = 4N\mu$, equal to $\rho$.

Deleterious mutations were introduced at rate $\rho/100$ per generation, drawing scaled selection
coefficients ($2Ns$)
from a Gamma distribution with a mean of -5 and a shape parameter of 1.  This distribution of fitness effects results in
thousands of weakly-deleterious mutations segregating in the population, many of which drift to intermediate
frequencies.  The case of many mutations with selection is a non-trivial violation of exchangeability assumptions of the
coalescent \citep{Neuhauser1997-nn}.  Therefore, these selected mutations must be explicitly tracked in our forward simulation
and the time savings due to pedigree recording come from not having to record \textit{neutral} mutations.

% When tracking neutral mutations (instead of the pedigree), run times increase dramatically with increasing region size ($4Nr = 4Nu$ for these simulations).
Pedigree tracking dramatically reduced runtimes, as shown in Fig~\ref{fig:runtimes_selection},
producing a relative speedup of up to around 50 fold relative to standard simulations that track neutral mutations
(Fig~\ref{fig:relative_speedup_selection}).
Pedigree tracking results in greater relative speedups for larger $N$
and we observe increasing relative speedups as $4Nr$ increases for a given $N$
(Fig~\ref{fig:relative_speedup_selection}).
Importantly, runtimes are approximately linear in region size $\rho$ when pedigree tracking
(partially obscured by the log scale of the horizontal axis in Fig~\ref{fig:runtimes_selection}).
%% don't know what an 'edge' is yet
% The reason for this behavior is that, when tracking pedigrees, the simulations are generating a constant number of new edges on average
% each generation as the number of new recombination breakpoints is Poisson distributed with expectation $\rho$.
In a more limited set of neutral simulations we found the same qualitative behavior,
and a numerically larger speedup by using pedigree tracking (see \nameref{ss:timing_nosel}).

In our implementation, simulations with pedigree recording
used substantially more RAM than simple forward simulations (see \nameref{ss:memuse}).
This is unsurprising:
unsimplified tree sequences grow quickly, and so storing history can use arbitrarily much memory.
However, this is not a requirement of the method, only a straightforwards consequence of a speed--memory tradeoff:
the amount of required memory is mostly determined by the interval between simplification steps,
but less frequent simplification reduces overall computation time (see \nameref{ss:gcinterval}).
In fact, our method could in some situations \emph{reduce} the amount of memory required,
if memory usage in the forwards simulation was dominated by the cost of maintaining neutral genetic variants.

\begin{figure}
    % \includegraphics[]{sims/rawspeed_logy}
    \caption{
        \label{fig:runtimes_selection}
    \textbf{Total run time per single simulation replicate as a function of region length.}
    % measured as the scaled recombination parameter $\rho = 4Nr$.
    Line color represents different diploid population sizes ($N$).
    The left figure shows run times for standard simulations including neutral mutations.
    The right column shows run times of simulations that recorded the pedigree
    and added neutral mutations afterwards.
    The dashed line in the right panel shows results for an implementation using \fwdpy{}
    where the pedigree simplification steps were handled in a separate thread of execution
    and fitness calculations were parallelized across four cores.
    Simulations with $N=5 \times 10^4$ timed out for region sizes larger than $10^3$.
    }
\end{figure}


\begin{figure}
    % \includegraphics[]{sims/speedup}
    \caption{
        \label{fig:relative_speedup_selection}
        \textbf{Relative speedup of simulations due to pedigree recording.}
        Each line shows the ratio of total run times of standard simulations to
        those of simulations with pedigree recording.
        Data points are taken from Fig~\ref{fig:runtimes_selection}
        for simulations that ran to completion in both cases.
    }
\end{figure}

% Maybe an estimate of how long \emph{just} the pedigree recording and simplification takes,
% so that then we can say how fast the simulator would have to be to do $10^6$
% whole chromosomes for $10^7$ generations in a day.



%%%%%%
\subsection*{Tables for succinct tree sequences}

We now explain what we actually did to achieve this $50\times$ speedup.
The ``pedigree recording'' simulations above recorded information about each new individual
in a collection of tables that together define a \emph{succinct tree sequence}
(or, simply ``tree sequence'').
A {tree sequence} is an encoding for a sequence of correlated trees,
such as those describing the history of a sexual population.
Tree sequences are efficient because branches that are shared by adjacent trees are stored once,
rather than repeatedly for each tree.
The topology of a tree sequence is defined via its \emph{nodes} and \emph{edges},
while information about variants is recorded as \emph{sites} and \emph{mutations};
we give an example in Fig~\ref{fig:example_tree_sequence}.
This formulation is derived from the ``coalescence records'' encoding of tree
sequences~\citep{kelleher2016efficient}, normalised to remove redundancy
and generalised to include a more general class of tree topologies.

The \emph{nodes} of a tree sequence
correspond to the vertices in the individual genealogies along the sequence.
Each node refers to a specific, distinct ancestor,
and so has a unique ``time'',
thought of as the node's birth time, which determines the height of any vertices
the node is associated with.
(Note that since each node time is equal to the amount of time since the {birth} of the
corresponding parent, time is measured in clock time, not in meioses.)
The example of Fig~\ref{fig:example_tree_sequence} has five nodes:
nodes 0, 1 and 2 occur at time 0 and are the \emph{samples},
while nodes 3 and 4 represent those ancestors necessary to record their genealogy,
who were born one and two units of time in the past, respectively.

\begin{figure}
    \begin{center}
        % \includegraphics[width=\textwidth]{example_tree_sequence}
    \end{center}
    \caption{
        \textbf{An example tree sequence with three samples over a chromosome of length 10.}
        The leftmost panels show the tree sequence pictorially in two different ways:
        (top) a sequence of tree topologies; the first tree extends from genomic position 0 to 5,
        and the second from 5 to 10; and
        (bottom) the edges that define these topologies,
        displayed over their corresponding genomic segment
        (for instance, the edge from node 2 to node 4 is present only on the interval from 0 to 5).
        The remaining panels show the specific encoding
        of this tree sequence in the four tables (nodes, edges, sites and mutations).
        \label{fig:example_tree_sequence}
    }
\end{figure}

The \emph{edges} define how nodes relate to each other over specific genomic intervals.
Each edge records
% is a tuple $(\ell, r, p, c)$, where
the endpoints $[\ell, r)$ of the half-open genomic interval defining the
spatial extent of the edge;
and the identities $p$ and $c$ of the parent and child nodes
of a single branch that occurs in all trees in this interval.
The spatial extent of the edges defining the topology of Fig~\ref{fig:example_tree_sequence}
are shown in the bottom left panel.
For example, the branch joining nodes 1 to 3 appears in both trees,
and so is recorded as a single edge extending over the whole chromosome.
It is this method of capturing the shared structure between adjacent trees that makes the
tree sequence encoding compact and algorithmically efficient.

Recovering the sequence of trees from this information is straightforward:
each point along the genome at which the tree topology changes
is accompanied by the end of some {edges} and the beginning of others.
Since each {edge} records the genomic interval
over which a given node inherits from a particular ancestor,
to construct the tree at a certain point in the genome
we need only retrieve all edges overlapping that point
and construct the corresponding tree.
To modify the tree to reflect the genealogy at a nearby location,
we simply remove those edges whose intervals do not overlap that location,
and add those new edges whose intervals do.
Incidentally, this property that edges naturally encode \emph{differences}
between nearby trees (e.g., as ``subtree prune and regraft'' moves)
allows for efficient algorithms to compute statistics of the genome sequence that take advantage
of the highly correlated nature of nearby trees~\citep{kelleher2016efficient}.

Given the topology defined by the nodes and edges, \emph{sites} and \emph{mutations}
encode the sequence information for each sample in an efficient way. Each site
records two things: its position on the genome and an ancestral state.
For example,
in Fig~\ref{fig:example_tree_sequence} we have two sites, one at position
2.5 with ancestral state `A' and the other at position 7.5 with ancestral state `G'.
If no mutations occur at a given site, all nodes inherit the ancestral state.
Each mutation records three things: the site at which it occurs,
the first node to inherit the mutation, and the derived state.
Thus, all nodes below the mutation's node in the tree will inherit this state,
unless further mutations are encountered.
Three mutations are shown in Fig~\ref{fig:example_tree_sequence},
illustrated by red stars.
The first site, in the left-hand tree,
has a single mutation, which results in node $2$ inheriting the state `T'.
The second site, in the right hand tree, has two mutations:
one occurring over node $3$ changing the state to `C',
and a back mutation over node $1$ changing the state to `G'.

This encoding of a sequence of trees and accompanying mutational information is
very concise. To illustrate this, we used \msprime{} to simulate 500,000 samples of a
$200$ megabase chromosome with human-like parameters: $N_e=10^4$ and per-base mutation and
recombination rates of $10^{-8}$ per generation. This resulted
in about 1 million distinct marginal trees and $1.1$ million infinite-sites
mutations. The HDF5 file encoding the node, edge, site and mutation tables (as
described above) for this simulation consumed 157MiB of storage space. Using
the \tskit{} Python API, the time required to load this file into memory was
around 1.5 seconds, and the time required to iterate over all 1 million trees
was 2.7 seconds. In contrast, recording the topological information in Newick
format would require around 20 TiB and storing the genotype information
in VCF would require about 1 TiB (giving a compression factor of 144,000 in
this instance).
Working with either the Newick or VCF encoding
of this dataset would likely require several
days of CPU time just to read the information into memory.

\paragraph{Validity of a set of tables}
Given a set of node and edge tables as described above,
there are only two requirements that ensure the tables
describe a valid tree sequence.
% (There are essentially no such requirements on the site and mutation tables.)
These are:
\begin{enumerate}
    \item Offspring must be born after their parents (and hence, no loops).
    \item The set of intervals on which each individual is a child must be disjoint.
\end{enumerate}
A pair of node and edge tables that satisfy these two requirements
is guaranteed to uniquely describe at each point on the genome
a collection of directed, acyclic graphs -- in other words, a forest of trees.
For some applications it is necessary to check that at every point
there is only a \emph{single} tree.
Checking this is more difficult, but is implemented in \tskit{}'s API.
For efficiency, \tskit{} makes several other sortedness requirements on the tables,
that are not necessarily satisfied by tables emitted by a forwards-time simulation.
\tskit{}'s API includes tools to rectify this by first sorting % (using \texttt{sort\_tables})
and then using the \texttt{simplify} algorithm described below, which works on sorted tables
and is guaranteed to produce a valid, \tskit{}-ready tree sequence.



%%%%%%
\subsection*{The \tskit{} Tables API}

The facilities for working with succinct tree sequences are implemented as part
of the \tskit{} Python API, which provides a powerful platform for processing
tree topology and mutation data. The portions of \tskit{} that we discuss
here are dedicated to tree sequence input and output using simple tables of
data, as described above, so we refer to this as the ``Tables API''.

The Tables API is primarily designed to facilitate efficient interchange of
data between programs or between different modules of the same program. We
adopted a `columnar' design, where all the values for a
particular column are stored in adjacent memory locations.
There are many advantages to columnar storage -- for example, since adjacent
values in memory are from the same column, they tend to compress well,
and suitable encodings can be chosen on a per-column basis~\citep{abadi2006integrating}.
A particular advantage of this approach is that it enables very
efficient copying of data, and in principle zero-copy data access
(where a data consumer reads directly from the memory of a producer).
Our implementation
% uses the NumPy C API~\citep{walt2011numpy} to efficiently copy
efficiently copies data from Python as a NumPy array \citep{walt2011numpy}
into the low-level C library used to manipulate tree sequences.
This architecture allows for data transfer rates of gigabytes per second
(impossible under any text-based approach), while retaining excellent portability.
NumPy's array interface provides a great deal of flexibility and efficiency,
and makes it straightforward to transfer data from sources
such as HDF5 \citep{hdf5} or Dask~\citep{dask}.
For small scale data and debugging purposes, a simple text based format is also supported.

The \tskit{} Python Tables API provides a general purpose toolkit for importing
and processing succinct tree sequences, and a collection of tutorials are being developed
at \url{https://github.com/tskit-dev/tutorials}. \linelabel{ll:tutorials}
Interoperation with Python simulators is then straightforward.  
The implementation we benchmark here uses \texttt{pybind11} 
(\url{https://github.com/pybind/pybind11/}) to interface with the \fwdpp{} \cpp{} API \citep{fwdpp}. 
No modifications were
required to the \fwdpp{} code base; rather, we simply need to bookkeep parent/offspring labels,
and perform simple processing of the recombination breakpoints from each mating
event to generate node and edge data. This information is then periodically copied
to the \tskit{} Tables API, where it is sorted and simplified.

\paragraph{Flexibility.}
To demonstrate the flexibility provided by the Tables API and provide an
implementation that decouples forward simulation internals from transfer of data
to \tskit, we also implemented a version of the simulations described in
``Simulation benchmarks'' separately in Python, described in \nameref{ss:simupop}.
In this proof-of-concept implementation, the simulation engine (we use \simupop{}, \citet{simupop})
invokes callbacks at critical points of the simulation, and we infer nodes and edges
from the information that is provided. Rows are appended to the tables
one-by-one, and the tables are periodically sorted and simplified to control
memory usage.
Benchmarking results from this implementation are shown (alongside results from \fwdpp{})
for simulations without selection in \nameref{ss:timing_nosel}:
a relatively modest speedup of around $5 \times$ is achieved, likely due to increased overhead.


%%%%%%
\subsection*{Recording the pedigree in forwards time}

To record the genealogical history of a forwards time simulation,
we need to record two things for each new chromosome:
the birth time; and the endpoints and parental IDs of each distinctly inherited segment.
These are naturally stored as the \emph{nodes} and \emph{edges} of a tree sequence.
To demonstrate the idea, we write out in pseudocode how to run a neutral Wright--Fisher simulation
that records genealogical history in this way.
The simulation will run for $T$ generations,
and has $N$ haploid individuals, each carrying a single chromosome of length $L$.
For simplicity, we sample exactly one crossover per generation.
Note that the \emph{table recording} portion of the algorithm does not depend on the Wright--Fisher
nature of the population simulation;  \linelabel{ll:not_wf}
next we will describe how to record tables from \emph{any} simulation.

We use $\randomuniform(A)$ to denote an element of the set $A$ chosen uniformly at random
(and all such instances are independent).
Given a node table $\Nt$, the function $\taddrow{\Nt}{t}$
adds a new node to the table $\Nt$ with time $t$
and returns the ID of this new node.
Similarly, the function $\taddrow{\Et}{\ell, r, p, c}$
adds a new edge $(\ell\text{eft}, r\text{ight}, p\text{arent}, c\text{hild})$ to the edge table $\Et$.
The function $\tsimplify{P, \Nt, \Et}$ (described below) % in section \ref{ss:simplify}
simplifies the history stored in the tables $\Nt$ and $\Et$
to the minimal information required to represent the genealogies of the list of node IDs $P$;
after simplification the nodes appearing in $P$ are relabeled $(0, 1, \ldots, |P|-1)$.
A step-by-step explanation follows the pseudocode.

\begin{taocpalg}{W}{Forwards-time tree sequence}
{Simulates a randomly mating population of $N$ haploid individuals with
chromosome of length $L$ for $T$ generations, and returns the node
and edge tables ($\Nt$ and $\Et$) recording the simulated history.
In each generation, the current population is stored in $P$,
while produced offspring are placed in $P'$.
The tables are simplified every $s$ generations, removing genealogical
information from $\Nt$ and $\Et$ irrelevant to the current population.
}

\algstep{W1.}{Initialisation.}{
    Set $\Nt \leftarrow \tnodetable{}$, $\mathcal{E}
    \leftarrow \tedgetable{}$, $t \leftarrow T$, and $j \leftarrow 0$.
 For $0 \leq k < N$, set $P_k \leftarrow \taddrow{\Nt}{T}$.
}

\algstep{W2.}{Generation loop head: new node.}{Set $u \leftarrow \taddrow{\Nt}{t}$ and $P'_j \leftarrow u$.
}

\algstep{W3.}{Choose parents.}{Set $a \leftarrow \randomuniform(\{0, \dots, N - 1\})$,
    $b \leftarrow \randomuniform(\{0, \dots, N - 1\})$ and $x \leftarrow \randomuniform((0, L))$.
}

\algstep{W4.}{Record edges.}{
Call $\taddrow{\Et}{0, x, P_a, u}$ and $\taddrow{\Et}{x, L, P_b, u}$.
}

\algstep{W5.}{Individual loop.}{Set $j \leftarrow j + 1$. If $j < N$ go to \algref{W2}.
Otherwise, if $t\bmod s \neq 0$ go to \algref{W7}.
}

\algstep{W6.}{Simplify.}{Call $\tsimplify{P', \Nt, \Et}$, and set $P'_k
    \leftarrow k $ for $0 \leq k < N$. } %% too cryptic: (Tables may need to be sorted.)

\algstep{W7.}{Generation loop.}{Set $t \leftarrow t - 1$. If $t = 0$ terminate.
Set $P \leftarrow P'$, $j \leftarrow 0$, and go to \algref{W2}.
}

\end{taocpalg}

We begin in~\algref{W1} by creating new node and edge tables, and setting
our population $P$ (a vector of $N$ node IDs) to the initial population.
This initial population is a set of $N$ nodes with birth time $T$ generations
ago. We also initialise our generation clock $t$ and individual index $j$.
Step~\algref{W2} replaces the $j^\text{th}$ individual (with node ID $P_j$)
by creating a new node with birth time $t$ (and ID $u$).
In step~\algref{W3} we determine the new node's ancestry
by choosing two indexes $a$ and $b$ uniformly,
giving us parental IDs $P_a$ and $P_b$,
and choose a chromosomal breakpoint $x$.
We record the effects of this event by storing two new edges: one recording that the parent of node $u$
from $0$ to $x$ is $P_a$, and another recording that the parent of $u$
from $x$ to $L$ is $P_b$. Step \algref{W5} then iterates these steps
for each of the $N$ individuals for each generation.
At the end of a generation, we then check
if we need to simplify (done every $s$ generations).
If simplification is required, we do this in step \algref{W6} by calling the simplify function
on the node and edge tables with the current set of population IDs $P'$ as the samples.
This updates the tables in-place to remove all redundant
information, and remaps the specified sample IDs to $0, \dots, N - 1$ in the updated tables.
Hence, we set our current population IDs to
$0, \dots N - 1$ after simplify has completed.
Step \algref{W7} loops these steps until the required number of generations have been simulated.
% then completes the algorithm by looping over generations;
% we decrement our clock $t$, and terminate if $t = 0$.
% Otherwise, we update our current population and individual index and loop
% back to \algref{W2}.


\begin{figure}
    \begin{center}
        % \includegraphics{wf-before-after}
    \end{center}
    \caption{
        \textbf{An example of a marginal genealogy from a Wright-Fisher simulation with $N=5$.}
        \textbf{(A)} the original tree including all
    intermediate nodes and dead-ends, and \textbf{(B)} the minimal tree
    relating all of the currently-alive individuals (27--31).
    \label{fig:wf-trees}
    }
\end{figure}


This algorithm records only topological information about the simulated genealogies,
but it is straightforward to add mutational information.
Mutations that occur during the simulation can be recorded
by simply storing the node in which they first occur, the derived state,
and (if not already present) the genomic position of the site at which it occurs.
This allows selected mutations, that the forwards time simulation must generate,
to be recorded in the tree sequence.
Neutral mutations can be generated after the simulation has completed, thus
avoiding the cost of generating the many mutations that are lost in the population.
This is straightforward to do because we have access to the marginal genealogies.

Fig~\ref{fig:wf-trees} shows
an example of a marginal genealogy produced by a forwards-time Wright--Fisher
process like Algorithm~\algref{W}.
On the left is the tree showing all the edges output by the simulation,
while on the right
is the minimal tree representing the ancestry of the current set of samples.
Clearly there is a great deal of redundancy in the topological
information output by the simulation.
This redundancy comes from two sources.
First, there are a large number of nodes in the tree that have only one child.
In Algorithm~\algref{W} we do not attempt to identify coalescence events,
but simply record all parent-child
relationships in the history of the population.
As such, many of these edges
will record the simple passing of genealogical information from parent to child
and only some small subset will correspond to coalescences within the marginal
trees. The second source of redundancy in the (unsimplified) output of Algorithm~\algref{W}
is due to the fact that lineages die out: a large number of
individuals in the simulation leave no descendants in the present day population.
Node 26 in Fig~\ref{fig:wf-trees}a, for example, leaves no
ancestors in the current population, and so the entire path tracing back to
its common ancestor with 27 is redundant.

\paragraph{Essential steps in tree sequence recording}
Since a tree sequence can record the history of genetic inheritance in any situation
(requiring only unambiguous inheritance and no time travel),
any individual-based population genetics simulator can maintain a tree sequence
with only a little bookkeeping. \revpoint{1}{1}
We have furthermore provided several tools to minimize this bookkeeping,
only requiring one-way output at the birth of each new individual.
Concretely, to record a tree sequence, including mutations,
a simulator must record for each new genome
(so, twice for each new diploid individual): \revpoint{1}{6}
\begin{itemize}
    \item the birth time of the genome in the Node Table,
    \item the segments the genome inherits from its parental genomes in the Edge Table,
    \item the locations of any new mutations in the Site Table,
    \item and the derived state of these new mutations in the Mutation Table
        (as well as the identity of this genome the mutations appeared in).
\end{itemize}
Each of these can be simply appended to the ends of the respective tables.
Besides this, simplification should be run every once in a while (e.g., every 100 generations).
Before simplification, time in the Node Table must be translated to ``time ago'' if it is not already.
(This was avoided in Algorithm~\algref{W} since there $t$ denoted
``time until the end of the simulation''.)
There are also several ``cleaning'' steps, for which we provide functions in the Tables API:
\emph{sorting} according to several criteria for algorithmic efficiency;
and removing any duplicate sites from the Site Table.
After simplification, since $\tsimplify{P', \Nt, \Et}$ results in the $N$ individuals in $P'$
being relabeled in \tskit{}'s tables as $0, 1, \ldots, N-1$,
there must be bookkeeping that keeps in sync the individual IDs as recorded by the simulator
with the node IDs recorded in the tables.

In other words, \linelabel{ll:other_words}
to record a tree sequence, a simulation needs only to know
(a) which genomes recombined to produce each new genome, and how;
(b) the locations and results of any new mutations on each genome;
and (c) the identities of every currently alive individual at each time simplification occurs.

\paragraph{Storing metadata}
Applications may also want to store more information not fitting into an existing column of the tables,
such as the selection coefficient of a mutation, or the sex of an individual.
This (and, indeed, arbitrary information) can be stored in the \texttt{metadata} columns
present in Node, Site, and Mutation tables. \revpoint{2}{8}


%%%%%%
\subsection*{Tree sequence simplification}
\label{ss:simplify}

It is desirable for many reasons to remove redundant information from a tree sequence.
To formalize this:
suppose that we are only interested in a subset of the nodes of a tree sequence
(which we refer to as our `samples'),
and wish to reduce this input tree sequence
to the smallest one that still completely describes the history of the specified samples,
having the following properties:
\begin{enumerate}

\item All marginal trees must match the subtree
        of the corresponding tree in the input tree sequence
        that is induced by the samples.

\item Within the marginal trees, all non-sample vertices must have at least
        two children (i.e., unary tree vertices are removed).

\item Any nodes and edges not ancestral to any of the sampled nodes are removed.

\item There are no adjacent redundant edges, i.e., pairs of edges
    $(\ell, x, p, c)$ and $(x, r, p, c)$ which can be represented with a single edge
    $(\ell, r, p, c)$.

\end{enumerate}


\begin{figure}
    \begin{center}
        % \includegraphics{method_diagram}
    \end{center}
    \caption{
        \textbf{An example of tree sequence simplification.}
        \textbf{(A)} The augmented pedigree diagram on the left
        relates the ten homologous chromosomes of five diploid individuals (BC, DE, FG, HI, and JK)
        to each other and to a common ancestral chromosome (A);
        dotted lines connect the two chromosomes of each individual,
        and solid lines lead to the products of their meioses.
        The corresponding tables (right) have 11 node records (one for each chromosome)
        and 15 edge records (one for each distinctly inherited segment).
        Blue numbers denote crossing over locations --
        for instance, $D$ and $E$ were parents to $G$,
        who inherited the left 70\% of the chromosome from $E$ and the remainder from $D$.
        $B$, $C$, $D$, and $E$ inherit clonally from $A$.
        \textbf{(B)} The five distinct trees
        found across the chromosome (blue numbers denote locations on the chromosome).
        Labels after simplification are shown in red (see text).
        \textbf{(C)} Tables recording the tree sequence after simplification
        with nodes $J$ and $K$ as samples.
        The mapping from labels in the forwards time simulation to nodes in the tree sequence
        is shown in red.
        % which allows additional records to be added as the simulation progresses.
        \label{fig:method_diagram}
    }
\end{figure}

Simplification is essential
not only for keeping the information recorded by forwards simulation manageable,
but also is useful for extracting subsets of a tree sequence representing a very large dataset.
% The tree sequences produced by forwards simulations
% record all of history for everyone alive at any time through the simulation.
% Simplification is essential to reduce this
% to a manageable quantity that still contains all
% the information that we are interested in.
% Simplification is also useful if we have a
% tree sequence representing a large dataset and wish to extract the
% information relevant to a subset of the samples.

We implement simplification by starting at the end of the simulation,
and moving back up through history,
recording in the new tree sequence only that information necessary to construct the tree sequence
of the specified individuals.
This process of tracing ancestry back through time in a pedigree
was the motivation for Hudson's coalescent simulation algorithm~\citep{hudson1983properties},
so it is unsurprising that simplification uses many of the same tools
as the implementation of Hudson's algorithm in \msprime{} \citep{kelleher2016efficient}.
The main difference is that events in a coalescent simulation are random, \revpoint{1}{2}
while in our simplification algorithm they are predetermined by history.
An implementation in pseudocode is provided in \nameref{ss:simplify_algorithm},
and a python implementation as supplementary information.

Conceptually, this works by
(a) beginning by painting the chromosome in each sample a distinct color;
(b) moving back through history,
copying the colors of each chromosome to the portions of its parental chromosomes
from which it was inherited;
(c) each time we would paint two colors in the same spot (a coalescence),
record that information as an edge and instead paint a brand-new color;
and
(d) once all colors have coalesced on a given segment,
stop propagating it.
This ``paint pot'' description misses some details --
for instance, we must ensure that all coalescing segments in a given individual
are assigned the \emph{same} new color --
but is reasonably close.
Fig~\ref{fig:method_diagram} shows an example tree sequence,
before and after simplification,
and Fig~\ref{fig:simplify_state} depicts the ``paint pot'' state of the algorithm
during the process of simplifying this tree sequence.
Since the method begins with the samples and moves back through time,
in the output tree sequence, the $n$ samples will be numbered $0, 1, \ldots, n-1$
and subsequent nodes will be ordered by time since birth.
This is seen in the red labels of Fig~\ref{fig:method_diagram}.


\begin{figure}
    \begin{center}
        % \includegraphics{simplify-state-diagram}
    \end{center}
    \caption{
        \textbf{A depiction of each state of the simplification algorithm}
        as it moves up through the embellished pedigree
        in the example of Fig~\ref{fig:method_diagram}A.
        Following the ``paint pot'' description in the text,
        we begin by coloring J and K's genomes in red and blue respectively,
        then trace how these colors were inherited back up through the pedigree
        until they coalesce.
        To aid in this,
        the smaller colored chromosomes on either side of each solid arrow
        show the bits inherited from each of the two parental chromosomes,
        with genomic position 0.0 on the bottom and 1.0 at the top.
        Each time a red and a blue segment overlap, a coalescence occurs, two edges are output,
        and we stop propagating that segment.
        For instance, both J and K inherit from H between 0.5 and 0.9,
        which resulted in the first two edges of the simplified table of Fig~\ref{fig:method_diagram}C.
        Later, both inherit from E between 0.2 and 0.5,
        along the paths J-H-G-E and K-I-E respectively,
        resulting in the next two edges.
        \label{fig:simplify_state}
    }
\end{figure}

More concretely,
the algorithm works by moving back through time,
processing each parent in the input tree sequence in chronological order.
The main state of the algorithm at each point in time is a set of ancestral lineages,
and each lineage is a linked list of ancestral segments.
An ancestral segment $(\ell, r, u)$ is found in a lineage
if the output node $u$ inherits the genomic interval $[\ell, r)$ from that lineage
(and so $u$ corresponds to a ``color'' in the description above).
% These segments are stored in a collection of linked lists,
% one list of segments for each ancestral lineage present at that time.
We also maintain a map from input nodes to lineages. % called $A_j$
Crucially, the time required to run the algorithm is
linear in the number of edges of the input tree sequence.

%%%%%%%%%%%%%%
\subsubsection*{Sequential simplification and prior history}
\label{ss:seq_simp}

Any simulation scheme that records data into tables,
as Algorithm~\algref{W} does,
has its genealogical history available at any time as a tree sequence.
This has two additional advantages:
First, simplification can be run periodically through the simulation,
if we take the set of samples to be the entire currently alive population.
This is important in practice as it keeps memory usage from growing linearly (and quickly) with time.
Second, the simulation can
be \emph{begun} with a tree sequence produced by some other method -- for
instance, by a coalescent simulation with \msprime,
providing an easy, efficient way to specify prior history.
A natural question is now: how often should simplification occur?
Limited testing (described in \nameref{ss:gcinterval})
found that different simplification intervals affect run times by approximately
25\%, with the lowest run time occurring when simplifying every $10^3$ generations.
Thus, there is a memory-versus-speed tradeoff
-- simplifying more often would keep fewer extinct nodes and edges in memory.

% As shown in the next section,
% there is no computational advantage to simplifying more often than is necessary
% to keep memory usage down.
%
% \krt{Empirically, I did find that simplifying more often than every 1,000 generations gave a run-time hit of about 25
% percent???}



%%%%%%%%%%%%
\subsubsection*{Computational complexity}

% I may need to cite my student's t-shirt for the following line:
%  "that's all very good in practice, but how does it hold up in theory?"
Fig \ref{fig:runtimes_selection} and Fig \ref{fig:relative_speedup_selection} show that this method
can dramatically improve simulation performance in practice --
but, how does it perform in theory?
% The simulation results shown in Figures \ref{fig:runtimes_selection} and \ref{fig:relative_speedup_selection} show that
% pedigree tracking greatly speeds up forward-time simulations.  Further, the run times with pedigree tracking become
% near-linear in $\rho$ (Figure \ref{fig:runtimes_selection}).
Both computational time and storage space are depend mostly
on the number of \emph{mutations} and \emph{edges} in the tree sequence.
% Each edge represents a segment of genome
% that has been inherited across a number of generations equal to the length of the edge.
% Each of these generations provided
% an opportunity for mutation and for recombination
% (which changes the tree, thus usually introducing a new edge).
% For this reason,
The key quantity to understand for this will be the total ``area'' of the tree sequence,
which is the sum of the lengths of all ancestral genomic segments that some, but not all,
of the present population has inherited.
It can be found by summing the product of segment length (left minus right coordinates)
and edge length (difference in birth times between parent and child),
across all edges.
This area is also equal to the sum of the total lengths of all marginal trees
(i.e., the trees describing inheritance at each position on the genome),
so can be computed as the sequence length multiplied by the mean marginal tree length.
Since we analyze tree sequences arising from a Wright--Fisher model,
statistical properties of a marginal tree are fairly well-described by coalescent theory.
Similar arguments to those below go back at least to \citet{watterson1975number},
who also explicitly computed smaller order corrections relevant to whole-population genealogies
of the Wright--Fisher model.
The arguments below are mostly self-contained,
but for an introduction to coalescent theory, including the basic facts used below,
see \citet{wakeley2005coalescent}.
\linelabel{ll:coal_signpost}


%% Memory reduction thanks to simplification
First: how much memory do simplified tree sequences require?
Consider a simulation of a Wright--Fisher population of $N$ haploid individuals
using Algorithm~\algref{W} for $T$ generations.
Since every chromosome inherits material from both parents,
without simplification this would produce tables of
$NT$ nodes and $2NT$ edges.
After simplification, we are left with the tree sequence describing the history
of only the current generation of $N$ individuals, back to either $T$ generations ago,
or their common ancestor, whichever comes first.
The tree sequence must store edges describing the leftmost marginal tree,
which requires at most $2N-2$ edges.
Then, each time the marginal tree changes along the sequence,
four edges end and four new edges begin
(except for changes affecting the root, which require fewer; see \citet{kelleher2016efficient}).
Suppose that $\mathcal{T}_x$ is the marginal tree at genomic position $x$,
and write $|\mathcal{T}_x|$ for the total length of the tree.
For the tree at nearby position $x + dx$ to be different,
there must have been a crossing-over between $x$ and $x + dx$
in one of the $|\mathcal{T}_x|$ meioses that gave birth to those individuals.
(Recall that these ``individuals'' are haploid.)
Since we measure distance along the genome
so that length is equal to the expected number of crossing-overs per generation,
the expected distance until the next crossing-over is $1/|\mathcal{T}_x|$.
If every crossing-over changed the marginal tree,
then this would imply, for consistency,
that the expected total number of times that the marginal tree changes along the genome
is equal to the total area of the tree sequence (as defined above).
Not every such crossing-over changes the marginal tree, but most do,
so the total area of the tree sequence,
multiplied by four,
gives an upper bound on the expected number of edges in the tree sequence
beyond those describing the leftmost tree.
Since we are considering a chromosome of length 1,
the expected total area is equal to the mean marginal tree length, as above.

If $T$ is large relative to $N$,
so that all marginal trees have a single root with high probability,
then coalescent theory tells us that
the expected total length of the branches of a marginal tree back to the most recent common ancestor
is approximately $2N\log(N)$.
Therefore, the tree sequence describing the entire population
is expected to need no more than $2N + 8N\log(N)$ edges.
Not every new edge derives from a never-before-seen node,
but the number of nodes is at most equal to the number of edges plus the sample size.
Therefore,
we would need $O(N^2)$ space to store the complete history of the simulation,
but only $O(N \log N)$ % $O(N + N \log N)$
to store the history that is relevant to the extant population.


%% Progressive memory reduction as a function of T
What if $T$ is smaller:
how many of the resulting $2NT$ edges are required after simplification?
In other words, how fast does the information in the pedigree become irrelevant?
% \citet{padhukasahasram2008exploring} obtained impressive speedups relative to contemporary simulators
% by retaining only 8 generations of history.
% This begs the question: how fast does the information in the pedigree become irrelevant?
Now, we need to compute the expected total length of all branches in a coalescent tree
up until time $T$ (or the common ancestor, whichever comes first).
Again, coalescent theory tells us that
the expected length of time for which a coalescent tree has $k$ lineages
is $2N/(k(k-1)) = 2N(1/(k-1) - 1/k)$ generations.
Since the tree has $k$ branches over this period,
it is expected to contribute $2N/(k-1)$ to the total tree length.
By summing over $n < k \le N$,
the $N$ tips of a tree are expected to descend from only $n$ lineages
around $2(N/n - 1)$ generations ago.
Inverting this relationship between time and number of roots
implies that a marginal tree cut $T$ units of time ago
% since 2N(1/n - 1/N) = 2(N/n-1) = T implies
%    N/n = (T+2)/2 and so n = 2N/(T+2)
is expected to have around $r(T)$ roots, where $r(T) = 2N/(T+2)$.
The total tree length over this time is
$2N \sum_{k=r(T)+1}^N 1/(k-1) \approx 2 N \log(N/r(T))$,
since $\sum_{k=1}^x 1/k \approx \log(x) + \gamma$.
This is a crude estimate for several reasons:
first, we should not count the branch leading to the root of the tree (i.e., when $r(T)=1$),
and second, this does not account for the discrete nature of the Wright--Fisher model.
% which is approximately
% \begin{align*}
%     2N - 2 + 8 N \left\{ \log(N-1) - \log(r(T)) \}
%        = 2N - 2 + 8 N \log( (T+2)(N-1)/2N )
%        \approx 2 N (1 + 4 \log( (T+2)/2 ))
% \end{align*}
Nonetheless, this leads as above to an upper bound on the number of edges of
\begin{align}
    \label{eqn:edge_bound}
    2 N \left( 1 + 4 \log\left( \min\left(N, \frac{T+2}{2}\right) \right)\right) .
\end{align}
This implies that the number of edges required to store the last $T$ generations
of history for the entire chromosome of a population of size $N$
grows as $O(N \log T)$ -- proportionally to $N$ at first but rapidly tapering off.
The bound holds up reasonably well in practice,
as shown in Fig~\ref{fig:simplify_complexity}.


\begin{figure}
    \begin{center}
        % \includegraphics{sims/simplify-results}
    \end{center}
    \caption{
        \textbf{Time and space complexity of simplify.}
        \textbf{(A)}
        Number of edges in the simplified tree sequence
        for 10 replicate Wright--Fisher simulations with $N=100$ as a function
        of number of generations.
        Each line is one simulation, the heavy blue line gives the average,
        and the dashed line is the upper bound of Eq~\eqref{eqn:edge_bound}.
        \textbf{(B)}
        Time required to simplify the first $k$ edges of a large (4.2GiB)
        unsimplified tree sequence produced by a forwards-time simulation plotted
        against $k$. The time scales linearly with the number of input edges.
        \textbf{(C)}
        Time required to simplify the tree sequence resulting from a coalescent
        simulation of 500,000 samples of a 200 megabase human chromosome
        to a random subsample of $n$ samples, plotted against $n$
        (note the log scale; the time scales logarithmically with $n$).
        \label{fig:simplify_complexity}
    }
\end{figure}

%% Above was edges; same holds for memory usage savings due to mutations
What about mutations?
Forwards-time generation of infinite-sites mutations with total mutation rate per generation $\mu$
would produce around $\mu N T$ mutations (and the same number of sites),
simply because there was a total of $N T$ meioses.
Since mutations that are retained after simplification
are precisely those that fall on the marginal trees,
the number of mutations is proportional to the total area of the tree sequence.
By the same argument as for the number of edges,
this will result in around $\mu 2 N \log(N)$ mutations.
With $N=2 \times 10^4$ and $T=10N$,
this implies that adding neutral mutations
to the simplified tree sequence reduces the number of mutations that must be generated
by a factor of 10,000.
This could result in substantial time savings,
even without considering the
computational burden of propagating mutations forwards across generations.

Since each mutation is stored only as a single row in the mutation table,
and at most one row in the site table, the space required for $M$ mutations is $O(M)$;
combined with the $O(N \log N)$ storage for edges and nodes of a simplified tree sequence,
this implies that the full results of a simulation of $N$ individuals
having $M$ mutations can be stored in $O(N \log N + M)$ space.
In simulations of whole chromosomes, there are typically a small, bounded number of mutations per chromosome per generation,
so $M$ will be $O(N \log N)$ as well.

%% simplify run time
How does the computation \emph{time} required for simplification scale?
Simply because it must process each edge,
% below per discussion
% https://github.com/petrelharp/ftprime_ms/pull/37#discussion_r156617283
the simplification algorithm is at least linear in the number of edges of the input tree sequence.
Empirically the algorithm is exactly linear,
as seen in Fig~\ref{fig:simplify_complexity}B,
which shows the time required to simplify increasingly large subsets of a large tree sequence.
When simplifying the result of a forwards-time sequence, the number of edges is the main contributing factor.
Suppose on the other hand we want to
simplify an already-minimal but large tree sequence with $N$ nodes
to a subsample of size $n$.
How does the required time scale with $n$?
In this case, the computation is dominated by the size of the output tree sequence,
which grows with $\log(n)$, as shown in Fig~\ref{fig:simplify_complexity}C.


%% the below assumes naive propagation of genotypes
% Our method stores genealogies, and so records substantially more information
% than would a method only recording genotypes.
% However, since the simplification algorithm requires computational effort,
% it is informative to compare time complexity of the algorithm
% to one that propagates neutral genotypes.
% A typical individual differs at around $2 N \mu$ sites from the population's consensus sequence,
% so propagating these to offspring by simple copying will take $4 N^2 \mu$ operations per generation.
% On the other hand,
% in our scheme we must store $13N$ quantities per generation (two edges and one node per individual).
% The simplification algorithm is linear in the number of edges of the input tree sequence
% (because it must process each edge),
% and so multiplies this by a constant factor.
% These considerations imply that propagating neutral genotypes for $T$ generations has time complexity $O(\mu T N^2)$,
% while our implementation is only $O(T N \log(2N))$.


%%%%%%%%%%%%%%%%%%%%%%
\section*{Discussion}

In this paper, we have shown that storing pedigrees
and associated recombination events
in a forwards-time simulation
not only results in having available a great deal more information about the simulated population,
but also can speed up the simulation by orders of magnitude.
To make this feasible,
we have described how to efficiently store this information in numerical tables,
and have described a fundamental algorithm for simplification of tree sequences.
Conceptually, recording of genealogical and recombination events
can happen independently of the details of simulation;
for this reason, we provide a well-defined and well-tested API in Python
for use in other code bases (a C API is also planned).

The tree sequences produced by default by this method
are very compact, storing genotype \emph{and} genealogical information
in a small fraction of the space taken by a compressed VCF file.
The format also allows highly efficient processing for downstream analysis.
Efficient processing is possible because many statistics of interest for population genetics
are naturally expressed in terms of tree topologies,
and so can be quickly computed from the trees underlying the tree sequence format.
For example, pairwise nucleotide diversity $\pi$, is the average density of
differences between sequences in the sample.
To compute this directly from sequence data at $m$ sites in $n$ samples
requires computing allele frequencies, taking $O(nm)$ operations.
By using the locations of the mutations on the marginal trees,
and the fact that these are correlated,
sequential tree algorithms similar to those in~\citep{kelleher2016efficient}
can do this in roughly $O(n + m + t \log n)$ operations, where
$t$ is the number of distinct trees.
The \tskit{} API provides a method to compute $\pi$ among arbitrary subsets of the
samples in a tree sequence, which took about 0.7 seconds when
applied to an example simulation of 100 megabases of human-like
sequence for 200,000 samples (about 500K sites). The corresponding
numeric genotype matrix required about 95GiB of RAM, and
calculating $\pi$ took about 66 seconds with NumPy.

% This is done by running $ python msprime-examples.py benchmark-pi

Another attractive feature of this set of tools
is that it makes it easy to incorporate \emph{prior history},
simply by seeding the simulation with a (relatively inexpensive) coalescent simulation.
This allows for incorporation of deep-time history beyond the reach of individual-based simulations.
This may not even negatively affect realism,
since geographic structure from times longer ago than the mixing
time of migration across the range has limited effect on modern genealogies
\citep{wilkins2004separation},
other than possibly changing effective population size \citep{barton2002neutral,cox2002stepping}.

% Simulating very large populations and entire genomes will likely require parallelization.
% The one-way nature of information flow here makes our scheme relatively easy to incorporate
% into a parallel algorithm.
% Recently, \citet{lawrie2017accelerating} used parallelization
% to improve performance for the ``Poisson Random Field'' family of models~\citep{Sawyer1992-jw},
% in which mutations are unlinked and there is no effect of genetic background on fitness.
% However, thus far little attention has been paid to parallelization of more complex simulations.

\paragraph{Other applications}
The methods described here for efficiently storing tree sequences may prove useful in other fields.
We have focused on the interpretation of tree sequences as the outcome of the process
of recombination, but in principle, we can efficiently encode any
sequence of trees which differ by subtree-prune-and-regraft
operations. Since each such operation requires a constant amount of space to encode, the total
space required is $O(n + t)$ for $t$ trees with $n$ leaves~\citep{kelleher2016efficient}.
For instance, the large numbers of large, correlated trees produced by
MCMC samplers used in Bayesian phylogenetics (e.g., \citet{drummond2012bayesian})
might be compactly stored as a tree sequence,
which would then allow highly efficient computation of properties of the posterior distribution.

In this article, we applied our methods for storing trees to the problem of pedigree recording in a forward-time
simulation.  However, the method applies to any simulation scheme generating nodes and edges.  For example, one could
use the methods described here to generate succinct tree sequences under coalescent processes not currently implemented
in \msprime{}, such as the coalescent with gene conversion \citep{Wiuf2000-rc}, using the structured coalescent to
model various forms of natural selection \citep{Kaplan1988-in,Kaplan1989-rt,Braverman1995-gn},
or the coalescent within a known pedigree.  For such models, one
could in principle generate tables of nodes and edges to be simplified in \tskit{}.  
The resulting succinct tree sequence object would be in the same format as those generated by \msprime{}'s simulate function,
and therefore compatible with existing methods for downstream analyses.

Another application of our methods would be the case of simulating coalescent histories conditional on known pedigrees.
The standard description of the Wright-Fisher coalescent averages over pedigrees.  However, conditional on a realized
pedigree, the distribution of coalescent times in the recent past differs from that of the unconditional coalescent
\citep{Wakeley2012-kw}.  For populations with known pedigrees (e.g., \citet{Aguillon2017-ac}), it may be of use to
simulate transmission along such pedigrees for the purpose of inference.

% JK: This needs more context. Probably not worth putting in here.
% \paragraph{Next steps.}
% While our methods result in significant performance
% gains over current simulation methods, they are far from optimal. Because
% forwards time simulation is highly CPU intensive, most simulation engines
% are written in \justc{} or \cpp{} out of necessity. Therefore, the simplest and most
% efficient approach would be to call the \tskit{} \justc{} library directly as part of
% the core simulation logic, in the manner outlined in Algorithm \algref{W}. If designed
% in this way, the simulation engine would not need to keep copies of the node and edge information.
% To facilitate this usage, we plan to release a standalone, embeddable \justc{} library encompassing the core
% tree sequence functionality, which should make recording and
% outputting tree sequences from any \justc{}/\cpp{} code straightforward.

\paragraph{A final note:}
in preparing this manuscript,
we debated a number of possible terms for the embellished pedigree,
i.e., the ``pedigree with ancestral recombination information'',
the object through which each tree of a tree sequence is threaded.
Etymological consensus \citep{liberman2014little} has
``pedigree'' derived from the french ``pied de grue'' for the foot of a crane
(whose branching pattern resembles the bifurcation of a single parent-offspring relationship).
An analogous term for the embellished pedigree might then be \emph{nedigree},
from ``nid de grue'',
as the nest of a crane is a large jumble of (forking) branches.
We thought it would be confusing to use this term throughout the manuscript,
but perhaps it will prove useful elsewhere.


%%%%%%%%%%%%%%
\section*{Methods}

We implemented simulations and the connection to \tskit{} in \cpp{}, using \fwdpp{} library functions and
interface code using a continuum-sites model for both mutation
and recombination. Simulations were run using \fwdpy{} (version 0.13.a0), a Python package based
on \fwdpp{} (version 0.5.7).  The majority of results are presented based on a single-threaded implementation.  However,
we also implemented a parallelized version using Python's \texttt{queue.Queue} to run the simplification step in a separate Python
thread. Our implementation allows a maximum of four simplification intervals to be in the queue at once. This
parallelized version also performed fitness calculation in parallel using two threads of execution in C++.

Code for all simulations and figures is available at \url{https://github.com/petrelharp/ftprime_ms}.
These made use of the GNU Scientific Library (version 1.16, \citet{galassi2018scientific}),
pybind11 (version 2.2.1, \citep{pybind11}),
and GCC (version 4.8.5).
We ran all benchmarks on an Ubuntu Linux (version 16.04) system with two 2.6 GHz Intel E5-2650 CPU with
hyperthreading enabled.
We ran one simulation at a time and the machine was under minimal load otherwise.
We used GNU parallel \citep{Tange2011a} to kill any simulation that did not finish within 72 hours,
and the Linux \texttt{time} command to record run time and peak memory usage of each replicate.
%% Our simulation scripts separately recorded the time spent in various steps of each run.


% \bibliography{references}

\begin{thebibliography}{10}

\bibitem{hudson1990gene}
Hudson RR.
\newblock Gene genealogies and the coalescent process.
\newblock Oxford surveys in evolutionary biology. 1990;7(1):44.

\bibitem{Neuhauser1997-nn}
Neuhauser C, Krone SM.
\newblock The genealogy of samples in models with selection.
\newblock Genetics. 1997;145(2):519--534.

\bibitem{barton2010new}
Barton NH, Kelleher J, Etheridge AM.
\newblock A new model for extinction and recolonization in two dimensions:
  quantifying phylogeography.
\newblock Evolution. 2010;64(9):2701--2715.

\bibitem{kelleher2014coalescent}
Kelleher J, Etheridge A, Barton N.
\newblock Coalescent simulation in continuous space: Algorithms for large
  neighbourhood size.
\newblock Theoretical population biology. 2014;95:13--23.

\bibitem{ray2010splatche2}
Ray N, Currat M, Foll M, Excoffier L.
\newblock {SPLATCHE2}: a spatially explicit simulation framework for complex
  demography, genetic admixture and recombination.
\newblock Bioinformatics. 2010;26(23):2993--2994.
\newblock doi:{10.1093/bioinformatics/btq579}.

\bibitem{martin2017human}
Martin AR, Gignoux CR, Walters RK, Wojcik GL, Neale BM, Gravel S, et~al.
\newblock Human demographic history impacts genetic risk prediction across
  diverse populations.
\newblock The American Journal of Human Genetics. 2017;100(4):635--649.

\bibitem{wakeley2003gene}
Wakeley J, Takahashi T.
\newblock Gene genealogies when the sample size exceeds the effective size of
  the population.
\newblock Mol Biol Evol. 2003;20(2):208--213.

\bibitem{maruvka2011recovering}
Maruvka YE, Shnerb NM, Bar-Yam Y, Wakeley J.
\newblock Recovering population parameters from a single gene genealogy: an
  unbiased estimator of the growth rate.
\newblock Mol Biol Evol. 2011;28(5):1617--1631.

\bibitem{bhaskar2014distortion}
Bhaskar A, Clark AG, Song YS.
\newblock Distortion of genealogical properties when the sample is very large.
\newblock Proc Natl Acad Sci USA. 2014;111(6):2385--2390.

\bibitem{harris2016genetic}
Harris K, Nielsen R.
\newblock The Genetic Cost of {Neanderthal} Introgression.
\newblock Genetics. 2016;203(2):881--891.

\bibitem{slim}
Messer PW.
\newblock {SLiM}: simulating evolution with selection and linkage.
\newblock Genetics. 2013;194(4):1037--1039.

\bibitem{Sanjak2017-ko}
Sanjak JS, Long AD, Thornton KR.
\newblock A Model of Compound Heterozygous, {Loss-of-Function} Alleles Is
  Broadly Consistent with Observations from {Complex-Disease} {GWAS} Datasets.
\newblock PLoS Genet. 2017;13(1):e1006573.

\bibitem{fwdpp}
Thornton KR.
\newblock A {C++} template library for efficient forward-time population
  genetic simulation of large populations.
\newblock Genetics. 2014;198(1):157--166.

\bibitem{wright1931evolution}
Wright S.
\newblock Evolution in {Mendelian} populations.
\newblock Genetics. 1931;16(2):97--159.

\bibitem{wakeley2005coalescent}
Wakeley J.
\newblock Coalescent Theory, an Introduction.
\newblock Greenwood Village, CO: Roberts and Company; 2005.
\newblock Available from: \url{http://www.coalescentheory.com/}.

\bibitem{haller2017flexible}
Haller BC, Messer PW.
\newblock {SLiM} 2: Flexible, Interactive Forward Genetic Simulations.
\newblock Molecular Biology and Evolution. 2017;34(1):230--240.
\newblock doi:{10.1093/molbev/msw211}.

\bibitem{Hernandez2015-wf}
Hernandez RD, Uricchio LH.
\newblock {SFS\_CODE}: More Efficient and Flexible Forward Simulations; 2015.

\bibitem{aberer2013rapid}
Aberer AJ, Stamatakis A.
\newblock Rapid forward-in-time simulation at the chromosome and genome level.
\newblock BMC Bioinformatics. 2013;14(1):216.
\newblock doi:{10.1186/1471-2105-14-216}.

\bibitem{padhukasahasram2008exploring}
Padhukasahasram B, Marjoram P, Wall JD, Bustamante CD, Nordborg M.
\newblock Exploring Population Genetic Models With Recombination Using
  Efficient Forward-Time Simulations.
\newblock Genetics. 2008;178(4):2417--2427.
\newblock doi:{10.1534/genetics.107.085332}.

\bibitem{griffiths1991two}
Griffiths RC.
\newblock The two-locus ancestral graph.
\newblock In: Selected Proceedings of the Sheffield Symposium on Applied
  Probability. vol.~18; 1991. p. 100--117.

\bibitem{griffiths1997ancestral}
Griffiths RC, Marjoram P.
\newblock An ancestral recombination graph.
\newblock In: Progress in population genetics and human evolution
  ({M}inneapolis, {MN}, 1994). vol.~87 of IMA Vol. Math. Appl. New York:
  Springer; 1997. p. 257--270.
\newblock Available from:
  \url{http://www.math.canterbury.ac.nz/~r.sainudiin/recomb/ima.pdf}.

\bibitem{wiuf1997number}
Wiuf C, Hein J.
\newblock On the number of ancestors to a {DNA} sequence.
\newblock Genetics. 1997;147(3):1459--1468.

\bibitem{wiuf1999ancestry}
Wiuf C, Hein J.
\newblock The ancestry of a sample of sequences subject to recombination.
\newblock Genetics. 1999;151(3):1217--1228.

\bibitem{marjoram2006coalescent}
Marjoram P, Wall JD.
\newblock Fast ``coalescent'' simulation.
\newblock BMC Genet. 2006;7:16--16.
\newblock doi:{10.1186/1471-2156-7-16}.

\bibitem{wilton2015smc}
Wilton PR, Carmi S, Hobolth A.
\newblock The {SMC'} Is a Highly Accurate Approximation to the Ancestral
  Recombination Graph.
\newblock Genetics. 2015;200(1):343--355.
\newblock doi:{10.1534/genetics.114.173898}.

\bibitem{kelleher2016efficient}
Kelleher J, Etheridge AM, McVean G.
\newblock Efficient coalescent simulation and genealogical analysis for large
  sample sizes.
\newblock PLoS computational biology. 2016;12(5):e1004842.

\bibitem{gog2014theory}
Gog S, Beller T, Moffat A, Petri M.
\newblock From theory to practice: Plug and play with succinct data structures.
\newblock In: International Symposium on Experimental Algorithms. Springer;
  2014. p. 326--337.

\bibitem{abadi2006integrating}
Abadi D, Madden S, Ferreira M.
\newblock Integrating compression and execution in column-oriented database
  systems.
\newblock In: Proceedings of the 2006 ACM SIGMOD international conference on
  Management of data. ACM; 2006. p. 671--682.

\bibitem{walt2011numpy}
Walt Svd, Colbert SC, Varoquaux G.
\newblock The {NumPy} array: a structure for efficient numerical computation.
\newblock Computing in Science \& Engineering. 2011;13(2):22--30.

\bibitem{hdf5}
{The HDF Group}. {Hierarchical Data Format, version 5}; 1997-2018.

\bibitem{dask}
{Dask Development Team}. Dask: Library for dynamic task scheduling; 2016.
\newblock Available from: \url{http://dask.pydata.org}.

\bibitem{simupop}
Peng B, Kimmel M.
\newblock simuPOP: a forward-time population genetics simulation environment.
\newblock Bioinformatics. 2005;21(18):3686--3687.

\bibitem{hudson1983properties}
Hudson RR.
\newblock Properties of a neutral allele model with intragenic recombination.
\newblock Theor Popul Biol. 1983;23:183--201.

\bibitem{watterson1975number}
Watterson GA.
\newblock On the number of segregating sites in genetical models without
  recombination.
\newblock Theor Popul Biol. 1975;7(2):256--276.

\bibitem{wilkins2004separation}
Wilkins JF.
\newblock A Separation-of-Timescales Approach to the Coalescent in a Continuous
  Population.
\newblock Genetics. 2004;168(4):2227--2244.
\newblock doi:{10.1534/genetics.103.022830}.

\bibitem{barton2002neutral}
Barton NH, Depaulis F, Etheridge AM.
\newblock Neutral Evolution in Spatially Continuous Populations.
\newblock Theoretical Population Biology. 2002;61(1):31--48.

\bibitem{cox2002stepping}
Cox JT, Durrett R.
\newblock The stepping stone model: New formulas expose old myths.
\newblock Ann Appl Probab. 2002;12(4):1348--1377.
\newblock doi:{10.1214/aoap/1037125866}.

\bibitem{drummond2012bayesian}
Drummond AJ, Suchard MA, Xie D, Rambaut A.
\newblock Bayesian phylogenetics with {BEAUti} and the {BEAST} 1.7.
\newblock Mol Biol Evol. 2012;29(8):1969--1973.
\newblock doi:{10.1093/molbev/mss075}.

\bibitem{Wiuf2000-rc}
Wiuf C, Hein J.
\newblock The Coalescent With Gene Conversion.
\newblock Genetics. 2000;155(1):451--462.

\bibitem{Kaplan1988-in}
Kaplan NL, Darden T, Hudson RR.
\newblock The coalescent process in models with selection.
\newblock Genetics. 1988;120(3):819--829.

\bibitem{Kaplan1989-rt}
Kaplan NL, Hudson RR, Langley CH.
\newblock The ``hitchhiking effect'' revisited.
\newblock Genetics. 1989;123(4):887--899.

\bibitem{Braverman1995-gn}
Braverman JM, Hudson RR, Kaplan NL, Langley CH, Stephan W.
\newblock The hitchhiking effect on the site frequency spectrum of {DNA}
  polymorphisms.
\newblock Genetics. 1995;140(2):783--796.

\bibitem{Wakeley2012-kw}
Wakeley J, King L, Low BS, Ramachandran S.
\newblock Gene genealogies within a fixed pedigree, and the robustness of
  Kingman's coalescent.
\newblock Genetics. 2012;190(4):1433--1445.

\bibitem{Aguillon2017-ac}
Aguillon SM, Fitzpatrick JW, Bowman R, Schoech SJ, Clark AG, Coop G, et~al.
\newblock Deconstructing isolation-by-distance: The genomic consequences of
  limited dispersal.
\newblock PLoS Genet. 2017;13(8):e1006911.

\bibitem{liberman2014little}
Liberman A. Little triumphs of etymology: ``pedigree''; 2014.
\newblock \url{https://blog.oup.com/2014/05/pedigree-etymology-word-origin/}.

\bibitem{galassi2018scientific}
{Galassi et al} M. GNU Scientific Library Reference Manual; 2018.
\newblock Available from: \url{https://www.gnu.org/software/gsl/}.

\bibitem{pybind11}
Jakob W, Rhinelander J, Moldovan D. {pybind11} -- Seamless operability between
  {C++11} and {Python}; 2016.

\bibitem{Tange2011a}
Tange O.
\newblock GNU Parallel - The Command-Line Power Tool.
\newblock ;login: The USENIX Magazine. 2011;36(1):42--47.

\end{thebibliography}

\section*{Supporting information}

\paragraph*{S1 Text}
\label{ss:timing_nosel}
\label{ss:memuse}
\label{ss:gcinterval}
\label{ss:simupop}
\label{ss:simplify_algorithm}
{\bf Additional benchmarks and algorithm listings.}
The supplementary text contains 
(A) benchmarking of run time and memory usage on simulations without selection;
(B) benchmarking of memory usage with selection;
(C) an analysis of the effect of simplification interval on run times;
(D) details for the \simupop{} implementation;
and (E) more details, and a listing, of the simplification algorithm.


%%%%%%%%%%%%%%%%%%%%%%
\section*{Acknowledgements}
Thanks to Gil McVean, Jared Galloway, Brad Shaffer, and Evan McCartney--Melstad for useful discussions.
% Work on this project was supported by funding from
% the Sloan Foundation and the NSF (under DBI-1262645) to PR;
% the Wellcome Trust (grant 100956/Z/13/Z) to Gil McVean;
% the NIH (R01GM115564) to KRT;
% and the USF\&WS to H.\ Bradley Shaffer.

\end{document}
